{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90b17c35-b75e-46f9-988c-8aaae9b39171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  date   HUFL   HULL   MUFL   MULL   LUFL   LULL         OT\n",
      "0  2016-07-01 00:00:00  5.827  2.009  1.599  0.462  4.203  1.340  30.531000\n",
      "1  2016-07-01 01:00:00  5.693  2.076  1.492  0.426  4.142  1.371  27.787001\n",
      "2  2016-07-01 02:00:00  5.157  1.741  1.279  0.355  3.777  1.218  27.787001\n",
      "3  2016-07-01 03:00:00  5.090  1.942  1.279  0.391  3.807  1.279  25.044001\n",
      "4  2016-07-01 04:00:00  5.358  1.942  1.492  0.462  3.868  1.279  21.948000\n",
      "Feature Engineering Complete:\n",
      "Total features: 18\n",
      "\n",
      "New features:\n",
      "['OT_diff', 'OT_diff_abs', 'OT_rolling_mean', 'OT_rolling_std', 'OT_rolling_max', 'OT_rolling_min', 'load_imbalance', 'voltage_imbalance', 'apparent_power', 'thermal_stress']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.signal import find_peaks\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Rolling statistics for temporal patterns\n",
    "window = 24  # 24 hours for daily patterns\n",
    "\n",
    "df = pd.read_csv(\"../data/ETTh1.csv\")\n",
    "print(df.head())\n",
    "\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# Rate of change features\n",
    "df['OT_diff'] = df['OT'].diff()\n",
    "df['OT_diff_abs'] = df['OT_diff'].abs()\n",
    "\n",
    "# Rolling statistics\n",
    "df['OT_rolling_mean'] = df['OT'].rolling(window=window, center=True).mean()\n",
    "df['OT_rolling_std'] = df['OT'].rolling(window=window, center=True).std()\n",
    "df['OT_rolling_max'] = df['OT'].rolling(window=window, center=True).max()\n",
    "df['OT_rolling_min'] = df['OT'].rolling(window=window, center=True).min()\n",
    "\n",
    "# Load imbalance indicators\n",
    "df['load_imbalance'] = df[['HUFL', 'MUFL', 'LUFL']].std(axis=1)\n",
    "df['voltage_imbalance'] = df[['HULL', 'MULL', 'LULL']].std(axis=1)\n",
    "\n",
    "P_high = np.sqrt(df['HUFL']**2 + df['HULL']**2)\n",
    "P_mid  = np.sqrt(df['MUFL']**2 + df['MULL']**2)\n",
    "P_low  = np.sqrt(df['LUFL']**2 + df['LULL']**2)\n",
    "\n",
    "df['apparent_power'] = np.sqrt(P_high**2 + P_mid**2 + P_low**2)\n",
    "\n",
    "# Thermal stress indicator (deviation from normal)\n",
    "df['thermal_stress'] = (df['OT'] - df['OT_rolling_mean']) / (df['OT_rolling_std'] + 1e-6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6500416-b31c-483d-82ac-247ff8bbeb8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Isolation Forest Anomalies: 174 (1.00%)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# Select features for Isolation Forest\n",
    "isolation_features = ['OT', 'apparent_power', 'load_imbalance', \n",
    "                     'voltage_imbalance', 'thermal_stress']\n",
    "\n",
    "# Remove NaN values from rolling calculations\n",
    "df_clean = df.dropna(subset=isolation_features).copy()  # .copy() prevents warnings\n",
    "\n",
    "# Standardize features\n",
    "scaler_iso = StandardScaler()\n",
    "X_iso = scaler_iso.fit_transform(df_clean[isolation_features])\n",
    "\n",
    "# Train Isolation Forest\n",
    "iso_forest = IsolationForest(\n",
    "    contamination=0.01,  # Expected proportion of outliers\n",
    "    random_state=42,\n",
    "    n_estimators=100\n",
    ")\n",
    "\n",
    "# Predict on clean data\n",
    "iso_predictions = iso_forest.fit_predict(X_iso)\n",
    "iso_scores = iso_forest.score_samples(X_iso)\n",
    "\n",
    "# Map back to original dataframe\n",
    "df['iso_anomaly'] = 1  # Default: normal\n",
    "df.loc[df_clean.index, 'iso_anomaly'] = iso_predictions\n",
    "df['iso_score'] = np.nan\n",
    "df.loc[df_clean.index, 'iso_score'] = iso_scores\n",
    "\n",
    "print(f\"Isolation Forest Anomalies: {(df['iso_anomaly'] == -1).sum()} \"\n",
    "      f\"({(df['iso_anomaly'] == -1).mean()*100:.2f}%)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
